# ğŸ“š Project Setup Guide

This guide will help you set up and run the Customer Churn Prediction System on your local machine.

## ğŸ”§ Prerequisites

Before you begin, ensure you have the following installed:

- **Python 3.9+** ([Download](https://www.python.org/downloads/))
- **Git** ([Download](https://git-scm.com/downloads))
- **Docker** (Optional, for containerized deployment)

## ğŸš€ Quick Start

### Option 1: Automated Setup (Recommended)

1. **Open Command Prompt** in the project directory

2. **Run the setup script:**

   ```batch
   setup.bat
   ```

3. **Run the ML pipeline:**

   ```batch
   run_pipeline.bat
   ```

4. **Start the services:**
   ```batch
   run_api.bat           # Start FastAPI (in one terminal)
   run_dashboard.bat     # Start Streamlit (in another terminal)
   run_mlflow.bat        # Start MLflow UI (in another terminal)
   ```

### Option 2: Manual Setup

1. **Create virtual environment:**

   ```bash
   python -m venv venv
   venv\Scripts\activate  # Windows
   # source venv/bin/activate  # Linux/Mac
   ```

2. **Install dependencies:**

   ```bash
   pip install -r requirements.txt
   ```

3. **Generate sample data:**

   ```bash
   python -m src.data_generation.generate_data
   ```

4. **Run feature engineering:**

   ```bash
   python -m src.feature_engineering.create_features
   ```

5. **Train models:**

   ```bash
   python -m src.training.train_models
   ```

6. **Start API:**

   ```bash
   uvicorn api.main:app --reload --port 8000
   ```

7. **Start Dashboard (new terminal):**
   ```bash
   streamlit run dashboard/app.py
   ```

## ğŸ“Š Accessing the Services

Once running, access the services at:

| Service       | URL                        | Description           |
| ------------- | -------------------------- | --------------------- |
| **FastAPI**   | http://localhost:8000      | Prediction API        |
| **API Docs**  | http://localhost:8000/docs | Swagger documentation |
| **Dashboard** | http://localhost:8501      | Streamlit UI          |
| **MLflow**    | http://localhost:5000      | Experiment tracking   |

## ğŸ³ Docker Deployment

To run with Docker:

```bash
# Build and start all services
docker-compose up -d

# View logs
docker-compose logs -f

# Stop services
docker-compose down
```

## ğŸ§ª Running Tests

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=src --cov-report=html
```

## ğŸ“ Project Structure

```
churn_e2e_ml/
â”œâ”€â”€ api/                 # FastAPI prediction service
â”œâ”€â”€ dashboard/           # Streamlit dashboard
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/            # Generated customer data
â”‚   â”œâ”€â”€ processed/      # Feature-engineered data
â”‚   â””â”€â”€ sample/         # Sample datasets
â”œâ”€â”€ docker/             # Dockerfiles
â”œâ”€â”€ models/
â”‚   â””â”€â”€ artifacts/      # Trained models
â”œâ”€â”€ mlruns/             # MLflow experiments
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_generation/    # Data generation code
â”‚   â”œâ”€â”€ feature_engineering/# Feature creation
â”‚   â”œâ”€â”€ training/           # Model training
â”‚   â””â”€â”€ utils/              # Helper functions
â”œâ”€â”€ tests/              # Unit tests
â”œâ”€â”€ config.yaml         # Configuration
â”œâ”€â”€ requirements.txt    # Dependencies
â””â”€â”€ docker-compose.yml  # Docker orchestration
```

## ğŸ”® Making Predictions

### Using the API

```python
import requests

customer = {
    "customer_id": "CUST_001",
    "tenure_months": 18,
    "monthly_spend": 250.50,
    "total_orders": 24,
    "avg_order_value": 85.00,
    "days_since_last_order": 15,
    "login_frequency": 12,
    "products_viewed": 25,
    "cart_abandonment_rate": 0.15,
    "support_tickets": 2,
    "discount_usage_rate": 0.3,
    "satisfaction_score": 7,
    "complaint_count": 1
}

response = requests.post("http://localhost:8000/predict", json=customer)
print(response.json())
```

### Using the Dashboard

1. Navigate to http://localhost:8501
2. Click on "ğŸ¯ Predictions" in the sidebar
3. Fill in the customer information
4. Click "ğŸ”® Predict Churn"

## â“ Troubleshooting

### Model not loading

Make sure you've run the training pipeline first:

```bash
run_pipeline.bat
```

### API returns 503

The model file doesn't exist. Run:

```bash
python -m src.training.train_models
```

### Port already in use

Kill the process using the port or use a different port:

```bash
uvicorn api.main:app --port 8001
```

## ğŸ“§ Support

If you encounter any issues, please open an issue on GitHub.
